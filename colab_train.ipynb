{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1. check and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install wget -y\n",
    "!sudo apt install libsndfile1-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip \n",
    "!python -m pip install flatbuffers==24.3.6\n",
    "!python -m pip install tensorflow==2.15.0\n",
    "!python -m pip install librosa\n",
    "!python -m pip install python_speech_features\n",
    "!python -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset path\n",
    "dataset_path = './data_speech_commands_v002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get speech_commands from google's server\n",
    "if not os.path.exists(dataset_path):\n",
    "    if not os.path.isfile('speech_commands_v0.02.tar.gz') :\n",
    "        !wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
    "    !mkdir data_speech_commands_v002\n",
    "    !tar zxf speech_commands_v0.02.tar.gz --checkpoint=1000 --checkpoint-action=\"echo=%T Unpacking... (%u/333756)\" --directory data_speech_commands_v002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# list the folders in the dataset\n",
    "dataset_dirslist = np.array(tf.io.gfile.listdir(str(dataset_path)))\n",
    "print ('dataset_dirslist:', dataset_dirslist,', num: ' , len(dataset_dirslist))\n",
    "print('-')\n",
    "\n",
    "# delete the files and folders which don't contain the trainable command folders from the list\n",
    "dataset_commands_dirslist = dataset_dirslist\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'README.md']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != '.DS_Store']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'validation_list.txt']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'testing_list.txt']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'LICENSE']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != '_background_noise_']\n",
    "print ('dataset_commands_dirslist:', dataset_commands_dirslist,', num: ' , len(dataset_commands_dirslist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. dataset commands filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the num of audio files in each command folder\n",
    "dataset_commands_filepaths = []\n",
    "for item in dataset_commands_dirslist:\n",
    "    dataset_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('dataset_commands_dir:', dataset_commands_dir)\n",
    "    fileslist = tf.io.gfile.glob(dataset_commands_dir)\n",
    "    print('file num of',item,':', len(fileslist))\n",
    "    dataset_commands_filepaths.extend(fileslist)\n",
    "    print('-')\n",
    "print('num of dataset_commands_filepaths:', len(dataset_commands_dirslist))\n",
    "print('num of dataset_commands_filepaths:', len(dataset_commands_filepaths))\n",
    "print('sample of dataset_commands_filepaths:', dataset_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Audio Preporcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-1. split num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the start index to split the dataset  \n",
    "def get_split_num(train_ratio = 0.8, val_ratio = 0.1, test_ratio = 0.1, file_num = 0):\n",
    "    #get train , val, test num\n",
    "    train_num = int( file_num * train_ratio )\n",
    "    val_num = int( file_num * val_ratio )\n",
    "    test_num = file_num - train_num - val_num \n",
    "\n",
    "    #get train , val, test first_num\n",
    "    train_first_num = 0\n",
    "    val_first_num = train_num\n",
    "    test_first_num = train_num + val_num\n",
    "    \n",
    "    return train_first_num, val_first_num, test_first_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-2. label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label from the filepath of audio file\n",
    "def get_label(filepath):\n",
    "    split_1=os.path.split(filepath)\n",
    "    split_2=os.path.split(split_1[0])\n",
    "    return split_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = get_label(dataset_commands_filepaths[0])\n",
    "print ('get_label(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-3. waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# load waveform from the filepath\n",
    "def get_waveform(filepath):\n",
    "    sample_rate = 16000\n",
    "    waveform, fs = librosa.load(filepath, sr=sample_rate)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = get_waveform(dataset_commands_filepaths[0])\n",
    "print ('get_waveform(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp.shape)\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-4. label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label id from label and command_list\n",
    "def get_label_id(label,command_list):\n",
    "    label_id = np.argmax(label==command_list)\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = get_label_id(get_label(dataset_commands_filepaths[0]),dataset_commands_dirslist)\n",
    "print ('get_label_id(get_label(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-5. MFCC-python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "def get_features(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    # input_len = 16000\n",
    "    # waveform = waveform[:input_len]\n",
    "    # np.shape(waveform) =  (16000,)\n",
    "    zero_padding = np.zeros( (16000-np.shape(waveform)[0],), dtype=np.float32)\n",
    "    # Cast the waveform tensors with np.float32\n",
    "    waveform = np.cast['float32'](waveform)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio clips are of the same length.\n",
    "    equal_length = np.concatenate([waveform, zero_padding], 0)\n",
    "    \n",
    "    sample_rate = 16000\n",
    "    num_mfcc = 16\n",
    "    len_mfcc = 40\n",
    "    mfccs = python_speech_features.base.mfcc(equal_length, \n",
    "                                            samplerate=sample_rate,\n",
    "                                            winlen=0.256,\n",
    "                                            winstep=0.050,\n",
    "                                            numcep=num_mfcc,\n",
    "                                            nfilt=26,\n",
    "                                            nfft=4096,\n",
    "                                            preemph=0.0,\n",
    "                                            ceplifter=0,\n",
    "                                            appendEnergy=False,\n",
    "                                            winfunc=np.hanning)\n",
    "    return mfccs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = get_features(get_waveform(dataset_commands_filepaths[0]))\n",
    "print ('get_features(get_waveform(dataset_commands_files[0])):')\n",
    "print ('type:',type(tmp))\n",
    "print ('shape:',tmp.shape)\n",
    "#print (tmp)\n",
    "fig = plt.figure()\n",
    "plt.imshow(tmp, cmap='inferno', origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Preporcess set commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1. get set command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(66)\n",
    "\n",
    "# set want commands\n",
    "commands = np.array(['on','stop'])\n",
    "\n",
    "train_set_commands_filepaths = []\n",
    "val_set_commands_filepaths = []\n",
    "test_set_commands_filepaths = []\n",
    "\n",
    "# get set commands\n",
    "set_commands_dirslist = commands\n",
    "# get the filepaths and split to train, val, test every command\n",
    "for item in set_commands_dirslist:\n",
    "    # join the dataset_path and command\n",
    "    set_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('set_commands_dir:', set_commands_dir)\n",
    "    \n",
    "    # list the set command filepaths in each dir\n",
    "    fileslist = tf.io.gfile.glob(set_commands_dir)\n",
    "    random.shuffle(fileslist)\n",
    "    print('file num :', len(fileslist))\n",
    "    print('-')\n",
    "    \n",
    "    # split the filslist to train, val, test\n",
    "    train, val, test = get_split_num(0.8, 0.1, 0.1, len(fileslist))\n",
    "    train_set_commands_filepaths.extend(fileslist[:val])\n",
    "    val_set_commands_filepaths.extend(fileslist[val:test])\n",
    "    test_set_commands_filepaths.extend(fileslist[test:])  \n",
    "# get the num of all tarinable audio files\n",
    "total_set_commands_num = len(train_set_commands_filepaths)+len(val_set_commands_filepaths)+len(test_set_commands_filepaths)\n",
    "    \n",
    "print('num of train_set_commands_filepaths:', len(train_set_commands_filepaths))\n",
    "print('num of val_set_commands_filepaths:', len(val_set_commands_filepaths))\n",
    "print('num of test_set_commands_filepaths:', len(test_set_commands_filepaths))\n",
    "\n",
    "print('total of set_commands_filepaths:',total_set_commands_num)\n",
    "print('sample of train_set_commands_filepaths:', train_set_commands_filepaths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. get features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_commands_features = []\n",
    "val_set_commands_features = []\n",
    "test_set_commands_features = []\n",
    "\n",
    "train_set_commands_label_id = []\n",
    "val_set_commands_label_id = []\n",
    "test_set_commands_label_id = []\n",
    " \n",
    "# get features and label id and append to train_set_commands_features and train_set_commands_label_id\n",
    "for i, item in enumerate(train_set_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    train_set_commands_features.append(features)\n",
    "\n",
    "    label = get_label(item)\n",
    "    label_id = get_label_id(label,commands)\n",
    "    train_set_commands_label_id.append(label_id)\n",
    "\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to train set commands... ({i+1}/{len(train_set_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to train set commands... ({i+1}/{len(train_set_commands_filepaths)})')\n",
    "\n",
    "# get features and label id and append to val_set_commands_features and val_set_commands_label_id\n",
    "for i, item in enumerate(val_set_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    val_set_commands_features.append(features)\n",
    "\n",
    "    label = get_label(item)\n",
    "    label_id = get_label_id(label,commands)\n",
    "    val_set_commands_label_id.append(label_id)\n",
    "\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to validation set commands... ({i+1}/{len(val_set_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to validation set commands... ({i+1}/{len(val_set_commands_filepaths)})')\n",
    "\n",
    "# get features and label id and append to test_set_commands_features and test_set_commands_label_id    \n",
    "for i, item in enumerate(test_set_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    test_set_commands_features.append(features)\n",
    "\n",
    "    label = get_label(item)\n",
    "    label_id = get_label_id(label,commands)\n",
    "    test_set_commands_label_id.append(label_id)        \n",
    "        \n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to test set commands...  ({i+1}/{len(test_set_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to test set commands...  ({i+1}/{len(test_set_commands_filepaths)})')\n",
    "\n",
    "print('-')\n",
    "print ('num of train_set_commands_features:', len(train_set_commands_features))\n",
    "print ('num of train_set_commands_label_id:', len(train_set_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_set_commands_features:', len(val_set_commands_features))\n",
    "print ('num of val_set_commands_label_id:', len(val_set_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_set_commands_features:', len(test_set_commands_features))\n",
    "print ('num of test_set_commands_label_id:', len(test_set_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features and label id to train list\n",
    "x_train.extend(train_set_commands_features)\n",
    "y_train.extend(train_set_commands_label_id)\n",
    "\n",
    "# add features and label id to val list\n",
    "x_val.extend(val_set_commands_features)\n",
    "y_val.extend(val_set_commands_label_id)\n",
    "\n",
    "# add features and label id to test list\n",
    "x_test.extend(test_set_commands_features)\n",
    "y_test.extend(test_set_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(y_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Preporcess unknown commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-1. get unknown command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unknown_commands_filepaths = []\n",
    "val_unknown_commands_filepaths = []\n",
    "test_unknown_commands_filepaths = []\n",
    "\n",
    "# add unknown to commands list\n",
    "if not np.any(commands=='unknown'):\n",
    "    commands = np.append(commands,'unknown')\n",
    "print ('commands:',commands)\n",
    "print('-')\n",
    "\n",
    "# get the unknown commands which are not set commands and add them to the list\n",
    "unknown_commands_dirslist = np.setdiff1d( dataset_commands_dirslist , commands)\n",
    "print ('unknown_commands_dirslist:',unknown_commands_dirslist)\n",
    "print('-')\n",
    "\n",
    "# set the ratio of unknown command filepaths to set command filepaths\n",
    "unknown_ratio = 0.1\n",
    "print('unknown_ratio:',unknown_ratio)\n",
    "print ('total_set_commands_num:', total_set_commands_num)\n",
    "# get the num of unknown command filepaths\n",
    "unknown_command_num = int(total_set_commands_num * unknown_ratio)\n",
    "print ('unknown_command_num:', unknown_command_num)\n",
    "# get the the num of each unknown command filepaths\n",
    "each_unknown_command_num = unknown_command_num//len(unknown_commands_dirslist)\n",
    "print ('each_unknown_command_num:', each_unknown_command_num)\n",
    "print('-')\n",
    "\n",
    "# get the filepaths and split to train, val, test every command\n",
    "for item in unknown_commands_dirslist:\n",
    "    # join the dataset_path and command\n",
    "    unknown_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('unknown_commands_dir:', unknown_commands_dir)\n",
    "    \n",
    "    # list the unknown command filepaths in each dir\n",
    "    fileslist = tf.io.gfile.glob(unknown_commands_dir)\n",
    "    random.shuffle(fileslist)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    # split the filslist to train, val, test\n",
    "    train, val, test = get_split_num(0.8, 0.1, 0.1, each_unknown_command_num)\n",
    "    train_unknown_commands_filepaths.extend(fileslist[:val])\n",
    "    val_unknown_commands_filepaths.extend(fileslist[val:test])\n",
    "    test_unknown_commands_filepaths.extend(fileslist[test:each_unknown_command_num])\n",
    "    print('-')\n",
    "    \n",
    "print('num of train_unknown_commands_filepaths:', len(train_unknown_commands_filepaths))\n",
    "print('num of val_unknown_commands_filepaths:', len(val_unknown_commands_filepaths))\n",
    "print('num of test_unknown_commands_filepaths:', len(test_unknown_commands_filepaths))\n",
    "print('sample of train_unknown_commands_filepaths:', train_unknown_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-2. get features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unknown_commands_features = []\n",
    "val_unknown_commands_features = []\n",
    "test_unknown_commands_features = []\n",
    "\n",
    "train_unknown_commands_label_id = []\n",
    "val_unknown_commands_label_id = []\n",
    "test_unknown_commands_label_id = []\n",
    "\n",
    "# get the unknown label and label_id\n",
    "label = 'unknown'\n",
    "label_id = get_label_id(label,commands)\n",
    "\n",
    "# get features and label id and append to train_unknown_commands_features and train_unknown_commands_label_id\n",
    "for i, item in enumerate(train_unknown_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    train_unknown_commands_features.append(features)\n",
    "    train_unknown_commands_label_id.append(label_id)\n",
    "\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to train unknown commands...  ({i+1}/{len(train_unknown_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to train unknown commands...  ({i+1}/{len(train_unknown_commands_filepaths)})')\n",
    "\n",
    "# get features and label id and append to val_unknown_commands_features and val_unknown_commands_label_id\n",
    "for i, item in enumerate(val_unknown_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    val_unknown_commands_features.append(features)\n",
    "    val_unknown_commands_label_id.append(label_id)\n",
    "\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to validation unknown commands...  ({i+1}/{len(val_unknown_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to validation unknown commands...  ({i+1}/{len(val_unknown_commands_filepaths)})')\n",
    "\n",
    "# get features and label id and append to test_unknown_commands_features and test_unknown_commands_label_id\n",
    "for i, item in enumerate(test_unknown_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    test_unknown_commands_features.append(features)\n",
    "    test_unknown_commands_label_id.append(label_id)        \n",
    "\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to test unknown commands...  ({i+1}/{len(test_unknown_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to test unknown commands...  ({i+1}/{len(test_unknown_commands_filepaths)})')    \n",
    "print('-')\n",
    "print ('num of train_unknown_commands_features:', len(train_unknown_commands_features))\n",
    "print ('num of train_unknown_commands_label_id:', len(train_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_unknown_commands_features:', len(val_unknown_commands_features))\n",
    "print ('num of val_unknown_commands_label_id:', len(val_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_unknown_commands_features:', len(test_unknown_commands_features))\n",
    "print ('num of test_unknown_commands_label_id:', len(test_unknown_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features and label id to train list\n",
    "x_train.extend(train_unknown_commands_features)\n",
    "y_train.extend(train_unknown_commands_label_id)\n",
    "# add features and label id to val list\n",
    "x_val.extend(val_unknown_commands_features)\n",
    "y_val.extend(val_unknown_commands_label_id)\n",
    "# add features and label id to test list\n",
    "x_test.extend(test_unknown_commands_features)\n",
    "y_test.extend(test_unknown_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(x_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Preporcess slience command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-1. get background command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slience_commands_filepaths = []\n",
    "val_slience_commands_filepaths = []\n",
    "test_slience_commands_filepaths = []\n",
    "\n",
    "# add slience command to commands list\n",
    "if not np.any(commands=='slience'):\n",
    "    commands = np.append(commands,'slience')\n",
    "print ('commands:',commands)\n",
    "print('-')\n",
    "\n",
    "# get background_noise to contruct slience samples\n",
    "slience_commands_dirslist = ['_background_noise_']\n",
    "print ('slience_commands_dirslist:',slience_commands_dirslist)\n",
    "print('-')\n",
    "\n",
    "# set the ratio of slience samples to set command filepaths\n",
    "slience_ratio = 0.1\n",
    "print ('total_set_commands_num:', total_set_commands_num)\n",
    "print('slience_ratio:',slience_ratio)\n",
    "# get the num of slience samples\n",
    "slience_command_num = int(total_set_commands_num * slience_ratio)\n",
    "print ('slience_command_num:', slience_command_num)\n",
    "print('-')\n",
    "\n",
    "# get the background_noise filepaths and append to train, val, test every filepaths\n",
    "for item in slience_commands_dirslist:\n",
    "    # join the dataset_path and background_noise files\n",
    "    slience_commands_dir = os.path.join(dataset_path, item,'*.wav')\n",
    "    print('slience_commands_dir:', slience_commands_dir)\n",
    "    \n",
    "    # get list of background_noise files\n",
    "    fileslist = tf.io.gfile.glob(slience_commands_dir)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    # get num of each background_noise files (the num to append for each files)\n",
    "    each_slience_files = slience_command_num//len(fileslist)\n",
    "    print ('each_slience_files:', each_slience_files)\n",
    "  \n",
    "    # get num of tarin , val ,test for each files\n",
    "    train_num = int(each_slience_files*0.8)\n",
    "    val_num = int(each_slience_files*0.1)\n",
    "    test_num = int(each_slience_files*0.1)\n",
    "    print('-')\n",
    "    \n",
    "    # every background_noise file\n",
    "    for itme in fileslist:\n",
    "        # append the filepath to train,val,test list for each files\n",
    "        for i in range(train_num):\n",
    "            train_slience_commands_filepaths.append(itme)\n",
    "        for i in range(val_num):\n",
    "            val_slience_commands_filepaths.append(itme)\n",
    "        for i in range(test_num):\n",
    "            test_slience_commands_filepaths.append(itme)\n",
    "\n",
    "print('num of train_slience_commands_filepaths:', len(train_slience_commands_filepaths))\n",
    "print('num of val_slience_commands_filepaths:', len(val_slience_commands_filepaths))\n",
    "print('num of test_slience_commands_filepaths:', len(test_slience_commands_filepaths))\n",
    "print('sample of train_slience_commands_filepaths:', train_slience_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-2. contruct slience features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ontruct slience features from background_noise\n",
    "def get_random_background_noise_waveform(filepath):\n",
    "    # get waveform and len from filepath\n",
    "    waveform = get_waveform(filepath)  \n",
    "    waveform_len = waveform.shape[0]\n",
    "    # get start time by random(waveform_len)\n",
    "    split_start_time = random.randrange(0, waveform_len)\n",
    "    # get the 1s background_noise sample to represent slience feature\n",
    "    waveform_split = waveform[split_start_time:split_start_time+16000]\n",
    "    return waveform_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contruct slience features by zero vector\n",
    "def get_zero_waveform():\n",
    "    # get the 1s zero vector sample to represent slience feature\n",
    "    zero_waveform = np.zeros((16000,), dtype=np.float32)\n",
    "    return zero_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slience_commands_features = []\n",
    "val_slience_commands_features = []\n",
    "test_slience_commands_features = []\n",
    "\n",
    "train_slience_commands_label_id = []\n",
    "val_slience_commands_label_id = []\n",
    "test_slience_commands_label_id = []\n",
    "\n",
    "# get the slience label and label_id\n",
    "label = 'slience'\n",
    "label_id = get_label_id(label,commands)\n",
    "\n",
    "# get features and label id by get_random_background_noise_waveform and append them to train list\n",
    "for i, item in enumerate(train_slience_commands_filepaths):\n",
    "    background_noise_waveform = get_random_background_noise_waveform(item)\n",
    "    features = get_features(background_noise_waveform)\n",
    "    train_slience_commands_features.append(features)\n",
    "    train_slience_commands_label_id.append(label_id)\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to train slience commands...  ({i+1}/{len(train_slience_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to train slience commands...  ({i+1}/{len(train_slience_commands_filepaths)})')    \n",
    "# get features and label id by get_zero_waveform and append one sample to train list\n",
    "zero_waveform = get_zero_waveform()\n",
    "features = get_features(zero_waveform)\n",
    "train_slience_commands_features.append(features)\n",
    "train_slience_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id by get_random_background_noise_waveform and append them to val list\n",
    "for i, item in enumerate(val_slience_commands_filepaths):\n",
    "    background_noise_waveform = get_random_background_noise_waveform(item)\n",
    "    features = get_features(background_noise_waveform)\n",
    "    val_slience_commands_features.append(features)\n",
    "    val_slience_commands_label_id.append(label_id)\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to validation slience commands...  ({i+1}/{len(val_slience_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to validation slience commands...  ({i+1}/{len(val_slience_commands_filepaths)})')      \n",
    "# get features and label id by get_zero_waveform and append one sample to val list\n",
    "zero_waveform = get_zero_waveform()\n",
    "features = get_features(zero_waveform)\n",
    "val_slience_commands_features.append(features)\n",
    "val_slience_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id by get_random_background_noise_waveform and append them to test list\n",
    "for i, item in enumerate(test_slience_commands_filepaths):\n",
    "    background_noise_waveform = get_random_background_noise_waveform(item)\n",
    "    features = get_features(background_noise_waveform)\n",
    "    test_slience_commands_features.append(features)\n",
    "    test_slience_commands_label_id.append(label_id) \n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'\\rget features and label id and append to test slience commands...  ({i+1}/{len(test_slience_commands_filepaths)})', end='')\n",
    "if (i+1)%10 != 0:\n",
    "    print(f'\\rget features and label id and append to test slience commands...  ({i+1}/{len(test_slience_commands_filepaths)})')     \n",
    "# get features and label id by get_zero_waveform and append one sample to test list\n",
    "zero_waveform = get_zero_waveform()\n",
    "features = get_features(zero_waveform)\n",
    "test_slience_commands_features.append(features)\n",
    "test_slience_commands_label_id.append(label_id)\n",
    "print('-')\n",
    "print ('num of train_slience_commands_features:', len(train_slience_commands_features))\n",
    "print ('num of train_slience_commands_label_id:', len(train_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_slience_commands_features:', len(val_slience_commands_features))\n",
    "print ('num of val_slience_commands_label_id:', len(val_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_slience_commands_features:', len(test_slience_commands_features))\n",
    "print ('num of test_slience_commands_label_id:', len(test_slience_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features and label id to train list\n",
    "x_train.extend(train_slience_commands_features)\n",
    "y_train.extend(train_slience_commands_label_id)\n",
    "# add features and label id to val list\n",
    "x_val.extend(val_slience_commands_features)\n",
    "y_val.extend(val_slience_commands_label_id)\n",
    "# add features and label id to test list\n",
    "x_test.extend(test_slience_commands_features)\n",
    "y_test.extend(test_slience_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(x_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5.  save and load processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets_file = 'all_targets_mfcc_sets.npz'\n",
    "# Save features and truth vector (y) sets to disk\n",
    "np.savez(feature_sets_file, \n",
    "         x_train=x_train, \n",
    "         y_train=y_train, \n",
    "         x_val=x_val, \n",
    "         y_val=y_val, \n",
    "         x_test=x_test, \n",
    "         y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets_path = './'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "# Load feature sets\n",
    "feature_sets = np.load(os.path.join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)\n",
    "# Assign feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip and shuffle \n",
    "train_list = list(zip(x_train, y_train))\n",
    "random.shuffle(train_list)\n",
    "x_train, y_train = zip(*train_list)\n",
    "\n",
    "val_list = list(zip(x_val, y_val))\n",
    "random.shuffle(val_list)\n",
    "x_val, y_val = zip(*val_list)\n",
    "\n",
    "test_list = list(zip(x_test, y_test))\n",
    "random.shuffle(test_list)\n",
    "x_test, y_test = zip(*test_list)\n",
    "\n",
    "# trans to np.array to expand dims\n",
    "x_tn = np.array(x_train)\n",
    "y_tn = np.array(y_train)\n",
    "x_v = np.array(x_val)\n",
    "y_v = np.array(y_val)\n",
    "x_ts = np.array(x_test)\n",
    "y_ts = np.array(y_test)\n",
    "\n",
    "# expand dims to satifiy input shape\n",
    "x_tn = np.expand_dims(x_tn, axis=-1)\n",
    "x_v = np.expand_dims(x_v, axis=-1)\n",
    "x_ts = np.expand_dims(x_ts, axis=-1)\n",
    "\n",
    "print (x_tn.shape)\n",
    "print (y_tn.shape)\n",
    "print (x_v.shape)\n",
    "print (y_v.shape)\n",
    "print (x_ts.shape)\n",
    "print (y_ts.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and check input shape by sampling \n",
    "tmp = get_features(get_waveform(dataset_commands_filepaths[0]))\n",
    "tmp = np.expand_dims(tmp, axis=-1)\n",
    "input_shape = tmp.shape\n",
    "print('Input shape:', input_shape)\n",
    "# get and check output shape by num of commands\n",
    "num_labels = len(commands)\n",
    "print('Output shape:', num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# build a model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    x_tn,y_tn,\n",
    "    validation_data=(x_v,y_v),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=64,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# determine overfitting by checking the metrics\n",
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6. save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model file name\n",
    "model_filename = 'SpeechCommandRecognition_model.h5'\n",
    "# Save the model as a file\n",
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-7. evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference on test set\n",
    "y_pred = np.argmax(model.predict(x_ts), axis=1)\n",
    "#print(y_pred)\n",
    "y_true = y_ts\n",
    "#print (y_true)\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8. display a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# check the result the confusion_matrix \n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=commands,\n",
    "            yticklabels=commands,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-9. run inference on an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on an audio file\n",
    "audio_file = os.path.join(dataset_path, 'on','0ba018fc_nohash_1.wav')\n",
    "sample_feature = get_features(get_waveform(audio_file))\n",
    "sample_feature = np.expand_dims(sample_feature, axis=-1)\n",
    "sample_feature = np.expand_dims(sample_feature, axis=0)\n",
    "\n",
    "sample_label = get_label(audio_file)\n",
    "sample_label_id = get_label_id(sample_label, commands)\n",
    "\n",
    "prediction = model(sample_feature)\n",
    "plt.bar(commands, tf.nn.softmax(prediction[0]))\n",
    "plt.title(f'Predictions for \"{commands[sample_label_id]}\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "# set the file name\n",
    "keras_model_filename = 'SpeechCommandRecognition_model.h5'\n",
    "tflite_filename = 'SpeechCommandRecognition_model.tflite'\n",
    "tflite_quantization_filename = 'SpeechCommandRecognition_quantization_model.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. convert (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "model = models.load_model(keras_model_filename)\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(tflite_filename, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(tflite_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
